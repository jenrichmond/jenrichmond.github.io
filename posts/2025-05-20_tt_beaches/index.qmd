---
title: "sydney beaches"
format: html
date: 2025-05-20
author: Jen Richmond
image: featured.png
---

My first TidyTuesday data curation!! This is an updated version of the dataset we used for [#RYouWithMe](https://rladiessydney.org/courses/), a series of online modules designed to get beginners into #rstats. I am excited to dig in and learn something new about what is going on with poo at Sydney beaches.

In poking about the BeachWatch website, I noticed that they have a key that gives each beach a star rating according to the bacteria levels and the risk to swimmers. 

I thought it might be interesting to look at different beach sites across the city and see how frequently each beach is rated as 4 stars "Good". 

I am most interested in data in the last 5 years so have filtered to only include reports from 2020 until 2025. 

![](key.png)



```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE,
                      dev = "ragg_png",
                      dpi = 400)
```


### read the data

Here I am reading the data from TidyTuesday, filtering for date, renaming the enterococci variable to make it a bit easier to deal with and adding a new column that codes each bug level as either Good, Fair, Poor, or Bad, according to the BeachWatch key.



```{r}
#| message: false
#| warning: false
#| code-fold: true
#| 
library(tidytuesdayR)
library(tidyverse)
library(janitor)
library(gt)
library(ggeasy)



my_colours <- RColorBrewer::brewer.pal(4, "RdYlGn")


water <- read_csv('https://raw.githubusercontent.com/rfordatascience/tidytuesday/main/data/2025/2025-05-20/water_quality.csv') %>%
  rename(bugs = enterococci_cfu_100ml) %>%
  mutate(stars = case_when(bugs < 41 ~ "Good", 
                            bugs > 500 ~ "Bad",
                           bugs %in% 41:200 ~ "Fair", 
                           bugs %in% 201:500 ~ "Poor", 
                           TRUE ~ "NA"
                           )) %>%
  filter(year(date) > 2019) %>%
  arrange(date)

glimpse(water)

# plot theme

theme_beaches <- function() { 
  
  theme_minimal() %+replace%
    theme(
      text = element_text(family = "Karla"), 
    plot.title = element_text(size = 16, hjust = 0.1, 
                              colour = "black",  margin = margin(b = 10)),
    plot.subtitle = element_text(size = 12, hjust = 0.1, 
                                 colour = "black",  margin = margin(b = 10)),
    plot.title.position = "plot",  # Position at the "plot" level rather than "panel"
    plot.subtitle.position = "plot",  # Position at the "plot" level rather than "panel"
    panel.background = element_rect(fill = "antiquewhite2", color = NA),
    plot.background = element_rect(fill = "antiquewhite2", color = NA),
    plot.margin = margin(t = 20, r = 20, b = 20, l = 20, unit = "pt"), 
    panel.grid.major = element_blank(),
    panel.grid.minor = element_blank(),
    legend.title = element_blank()
      )
    
}


```




## how many days are good for swimming

### city beaches

In the [#RYouWithMe modules](https://rladiessydney.org/courses/), we used data from the Sydney City beaches, so I am going to start with those because I am a bit more familiar with them. 

#### raw count

Here I am filtering the water data to include only beaches that are within the Sydney city region and using the `tabyl` function from the `janitor` package to count how often each site was rated Good, Fair, Poor, and Bad. Then I make that data long and fix the order of the rating levels, before plotting. 

```{r}
#| code-fold: true


city <-  water %>%
  filter(region == "Sydney City") 

good_days_city <- city %>%
 tabyl(swim_site, stars) %>%
  select(swim_site, Good, Fair, Poor, Bad) 


good_days_city_long <- good_days_city %>%
  pivot_longer(names_to = "rating", values_to = "count", Good:Bad) %>%
  mutate(rating = fct_relevel(rating, c("Bad", "Poor", "Fair", "Good"))) 


good_days_city_long %>%
    ggplot(aes(x = reorder(swim_site, count), y = count, fill = rating)) +
  geom_col() +
   scale_fill_manual(values = my_colours) +
  coord_flip() +
  labs(x = "Beach", y = "Count of ratings", title = "Water quality at Sydney City Beaches", 
        subtitle= "Data from BeachWatch NSW 2020-2025") +
  theme_beaches()



```

#### percent

Across 2020-2025, there is a small amount of variability in the number of readings that each beach site has so I am going to tweak this to plot percent rather than raw data. I have also ordered the bars so that the beaches that have the highest percent Good ratings are at the top. 



```{r}
#| code-fold: true

good_days_city_long_percent <- good_days_city %>%
  pivot_longer(names_to = "rating", values_to = "count", Good:Bad) %>%
  mutate(rating = fct_relevel(rating, c("Bad", "Poor", "Fair", "Good"))) %>%
  group_by(swim_site) %>%
  mutate(total_days = sum(count)) %>%
  rowwise() %>%
  mutate(percent = count/total_days) %>%
   group_by(swim_site) %>%
  mutate(good_percent = percent[rating == "Good"]) %>% #pull good % for use in reorder
  ungroup()


good_days_city_long_percent %>%
    ggplot(aes(x = reorder(swim_site, good_percent), y = percent, fill = rating)) +
  geom_col() +
   scale_fill_manual(values = my_colours) +
  coord_flip() +
  labs(x = "Beach", y = "Percent of ratings", title = "Water quality at Sydney City Beaches", 
       subtitle= "Data from BeachWatch NSW 2020-2025") +
    theme_beaches()

```


It is a bit disconcerting that Coogee beach (where I used to live) is only rated "Good" 75% of the time. 


### all regions

Now I would like to get a plot like this for all the other regions. It is interesting that there are so many data points for Northern Sydney and hardly any for Western Sydney, so that might be something to dig into too. 

```{r}

water %>%
  tabyl(region) %>%
  gt()

```

I would like to count the number of times each swim site gets each star rating but keep information about which region the beach belongs too so I can compare regions.  

If I use `water %>% tabyl(swim_site, stars)` the output drops information about the region. 

But if I add region as an argument to the `tabyl()` function, the output ends up being a list. 

```{r}

good_days_region <- water %>%
 tabyl(swim_site, stars, region)


class(good_days_region)


```

Maybe I write a function that will apply the cleaning process and then make a plot for each region in the list. 


My function takes two arguments: the data and names of the regions. It has a processing step which filters out sites that have missing data across the board, selects just relevant variables, makes the data long, and fixes the levels of the quality. The output of that step (processed_df) is fed into the plot. 

```{r raw function}
#| code-fold: true

plot_region_data_raw <- function(df, region_name) {
  
  processed_df <- df %>%
    filter(Bad > 0 | Fair > 0 | Good > 0 | Poor > 0) %>%
    select(swim_site, Good, Fair, Poor, Bad) %>%
    pivot_longer(names_to = "rating", values_to = "count", Good:Bad) %>%
    mutate(rating = fct_relevel(rating, c("Bad", "Poor", "Fair", "Good"))) 
    
   
  plot <- ggplot(processed_df, 
                 aes(x = reorder(swim_site, count), 
                     y = count, fill = rating)) +
    geom_col() +
     scale_fill_manual(values = my_colours) +
    coord_flip() +
    labs(
      title = paste("Water Quality Ratings in", region_name),
      subtitle= "Data from BeachWatch NSW 2020-2025",
      x = "Beach",
      y = "Count of ratings",
      fill = "Rating"
    ) +
    theme_beaches() 
  
  return(plot)
}
```

Once I have the function in my enviornment, I can use `map2()` from `purrr` to run the processing/plot function on each of the regions in the list and output a list of plots. 

```{r}
#| code-fold: true
region_plots_raw <- map2(good_days_region,  # the list 
  names(good_days_region),  # the names of each list element
  plot_region_data_raw # function to map 
)

```


#### Water Quality by region: Count of ratings

::: panel-tabset

#### Northern Sydney

```{r}
#| echo: false
region_plots_raw[[1]]
```


#### Southern Sydney

```{r}
#| echo: false
region_plots_raw[[2]]
```


#### Sydney City

```{r}
#| echo: false
region_plots_raw[[3]]
```

#### Sydney Harbour

```{r}
#| echo: false
region_plots_raw[[4]]
```

#### Western Sydney

```{r}
#| echo: false
region_plots_raw[[5]]
```
:::


It is curious that Western Sydney has so many fewer data points than other regions, but it also makes it worth repeating the plots with percents. 

```{r percent function}
#| code-fold: true

plot_region_data_percent <- function(df, region_name) {
  processed_df <- df %>%
    filter(Bad > 0 | Fair > 0 | Good > 0 | Poor > 0) %>%
    select(swim_site, Good, Fair, Poor, Bad) %>%
    pivot_longer(names_to = "rating", values_to = "count", Good:Bad) %>%
    mutate(rating = fct_relevel(rating, c("Bad", "Poor", "Fair", "Good"))) %>%
     group_by(swim_site) %>%
  mutate(total_days = sum(count)) %>%
  rowwise() %>%
  mutate(percent = count/total_days) %>%
   group_by(swim_site) %>%
  mutate(good_percent = percent[rating == "Good"]) %>% #pull good % for use in reorder
  ungroup()
  
  plot <- ggplot(processed_df, 
                 aes(x = reorder(swim_site, good_percent), y = percent, fill = rating)) +
    geom_col() +
     scale_fill_manual(values = my_colours) +
    coord_flip() +
    labs(
      title = paste("Water Quality Ratings in", region_name),
      subtitle= "Data from BeachWatch NSW 2020-2025",
      x = "Beach",
      y = "Percent of ratings",
      fill = "Rating"
    ) +
    theme_beaches() 
  
  return(plot)
}


region_plots_percent <- map2(good_days_region,  # list of data frames
  names(good_days_region),  # Names of each list element
  plot_region_data_percent # function to map 
)



```

#### Water Quality by region: Percent of ratings

::: panel-tabset

#### Northern Sydney

```{r}
#| echo: false
region_plots_percent[[1]]
```


#### Southern Sydney

```{r}
#| echo: false
region_plots_percent[[2]]
```


#### Sydney City

```{r}
#| echo: false
region_plots_percent[[3]]
```

#### Sydney Harbour

```{r}
#| echo: false
region_plots_percent[[4]]
```

#### Western Sydney

```{r}
#| echo: false
region_plots_percent[[5]]


```
:::




```{r ggsave chunk}
#| include: false

city <- region_plots_percent[[3]]

west <- region_plots_percent[[5]]

long_city <- "Sydney City ocean beaches, in the affluent Eastern Suburbs, are rated as Good for swimming on at least 75% of testing days. "

# Wrap at 80 characters (you can tweak this)
subtitle_city <- str_wrap(long_city, width = 110)


city2 <- city +
  labs(title = "Water Quality by Sydney region", 
       subtitle = subtitle_city, x = "") +
  easy_remove_legend() +
  theme(plot.margin = margin(t = 20, r = 20, b = 5, l = 20), 
    plot.title.position = "plot",    # Align title and subtitle together
    plot.title = element_text(hjust = 0),
    plot.subtitle = element_text(hjust = 0.1)
  )
 

city2

long_west <- "In Western Sydney, where swimming sites are creeks and rivers, only Penrith Beach is frequently safe to swim."

# Wrap at 80 characters (you can tweak this)
subtitle_west <- str_wrap(long_west, width = 110)

west2 <- west +
  labs(title = "",
    caption = "Data from BeachWatch NSW 2020-2025", 
        subtitle = subtitle_west, x = "") +
  easy_move_legend(to = c("bottom")) +
 scale_fill_manual(
    values = c(
      "Bad" = "#D7191C",
      "Poor" = "#FDAE61",
      "Fair" = "#A6D96A",
      "Good" = "#1A9641"
    ),
    breaks = c("Good", "Fair", "Poor", "Bad") ) +
  theme(plot.margin = margin(t = 5, r = 20, b = 20, l = 20), 
        plot.title.position = "plot",    # Align title and subtitle together
    plot.title = element_text(hjust = 0),
    plot.subtitle = element_text(hjust = 0.1)
  )
    
    
west2

library(patchwork)

city2 / west2 


ggsave(here::here("posts", "2025-05-20_tt_beaches", "toshare.png"),
       width = 10, height = 8,  bg = "antiquewhite2")



```



## what is going on in Western Sydney?

The data presented above show that Western Sydney beaches have many fewer data points than beaches in other regions.  

It got me thinking about potential differences in testing frequency. Here I am computing a new variable that calcuates the time between sucessive data points using the `difftime()` function. 

```{r}
#| code-fold: true
#| 
freq <- water %>%
  select(region, swim_site, bugs, stars, date) %>%
  arrange(swim_site, date) %>%
 mutate(testing_gap = difftime(date, lag(date), units = "days")) %>%
  mutate(testing_gap = as.numeric(testing_gap)) %>%
  filter(testing_gap > 0)

freq %>%
  group_by(region) %>%
  summarise(mean_time_lapsed = mean(testing_gap, na.rm= TRUE)) %>%
  gt()
```

It is clear that while the water quality in most regions is tested about once a week, in Western Sydney data points come in on average every 18 days. Is that because the frequency of testing is genuinely lower in Western Sydney, or are there gaps in the data?

This plot would suggest the latter is true. 

```{r}
#| code-fold: true
#| 
ws <- freq %>%
  filter(region == "Western Sydney") 


ws %>%
  ggplot(aes(x = date, y= testing_gap)) +
  geom_point() +
  geom_line() +
  facet_wrap(~swim_site) +
  theme_minimal() +
  labs(title = "Days between data points in Western Sydney", x = "Date", y = "Testing gap")
```

In fact, if we look at the number of data points in the dataset per month, it is clear that in Western Sydney, at some beach sites, testing is seasonal and only happens in the summer. 

```{r}
#| message: false
#| warning: false
#| code-fold: true


ws_monthly_count <- ws %>%
  mutate(month = month(date, label = TRUE)) %>%
  group_by(month, swim_site) %>%
  summarise(count = n()) 


ws_monthly_count %>%
  ggplot(aes(x = month, y = count)) +
  geom_point() +
  facet_wrap(~swim_site) +
  theme_minimal() +
  labs(title = "Water quality testing is seasonal in Western Sydney", x = "Month", y = "Count")
```

